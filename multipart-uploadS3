import boto3
import requests
import hashlib

def download_and_upload_ova(url, bucket_name, s3_key, chunk_size=1024*1024*50):  # 50 MB chunks
    # Initialize S3 client
    s3_client = boto3.client('s3')

    # Hashing object to ensure integrity
    sha256_hash = hashlib.sha256()

    try:
        # Streaming download from the provided URL
        with requests.get(url, stream=True) as response:
            response.raise_for_status()
            
            # Initialize the S3 file upload by writing data directly using put_object
            file_position = 0  # Track the position within the file
            
            # Reading the file in chunks and uploading each chunk
            for chunk in response.iter_content(chunk_size=chunk_size):
                if not chunk:
                    break  # End of file
                
                sha256_hash.update(chunk)  # Update hash for integrity check
                
                # Upload each chunk directly using put_object
                s3_client.put_object(
                    Bucket=bucket_name,
                    Key=s3_key,
                    Body=chunk,
                    ContentRange=f"bytes {file_position}-{file_position + len(chunk) - 1}/{file_position + len(chunk)}"
                )
                
                file_position += len(chunk)

    except requests.exceptions.RequestException as e:
        print(f"HTTP Request failed: {e}")
        return None

    except boto3.exceptions.Boto3Error as e:
        print(f"Error uploading to S3: {e}")
        return None

    # After the upload is complete, print the SHA-256 hash
    print(f"SHA-256 Hash of OVA: {sha256_hash.hexdigest()}")

    return bucket_name, s3_key


# Example usage
url = "https://example.com/path-to-large-ova-file.ova"
bucket_name = "your-s3-bucket"
s3_key = "path-in-s3/large-ova-file.ova"

bucket, key = download_and_upload_ova(url, bucket_name, s3_key)
print(f"File uploaded to S3: s3://{bucket}/{key}")
