import boto3
import requests
import hashlib
import threading
import sys
from boto3.s3.transfer import TransferConfig

# Function to download the OVA file from a URL, calculate hash, and upload it to S3 using multipart upload
def multi_part_upload_with_s3_from_url(bucket_name, s3_key, download_url):
    try:
        # Get the response and total size of the file from the URL
        response = requests.get(download_url, stream=True)
        response.raise_for_status()  # Ensure there is no error in downloading the file
        
        total_size = int(response.headers.get('content-length', 0))
        
        if total_size == 0:
            print("Warning: Couldn't fetch file size from the URL. Progress tracking will be disabled.")
        
        # Set chunk size to 500 MB
        min_chunk_size = 500 * 1024 * 1024
        chunk_size = max(min_chunk_size, total_size // 10000 if total_size > 0 else min_chunk_size)
        
        # Multipart upload configuration
        config = TransferConfig(
            multipart_threshold=chunk_size,
            multipart_chunksize=chunk_size,
            max_concurrency=10,
            use_threads=True
        )
        
        # Initialize S3 resource
        s3 = boto3.resource('s3')
        file_obj = response.raw
        
        # Calculate hash for verification
        original_hash = calculate_sha256_hash(requests.get(download_url, stream=True), total_size)
        print(f"Original file SHA256 hash: {original_hash}")

        # Reset the stream to the beginning for uploading
        response = requests.get(download_url, stream=True)
        response.raise_for_status()  # Ensure no errors
        
        # Track progress and upload file
        callback = ProgressPercentage(total_size)
        s3.meta.client.upload_fileobj(
            file_obj,
            bucket_name,
            s3_key,
            Config=config,
            Callback=callback if total_size > 0 else None,
            ExtraArgs={'ContentType': 'application/octet-stream'}
        )

        # Verify file size after upload
        s3_file_size = s3.Object(bucket_name, s3_key).content_length
        print(f"S3 file size: {s3_file_size / (1024 * 1024 * 1024)} GB")
        print("Upload completed. Now verifying file integrity...")

        # Recalculate hash by downloading the file back from S3
        s3_hash = calculate_sha256_hash_from_s3(bucket_name, s3_key)
        print(f"S3 file SHA256 hash: {s3_hash}")

        # Compare the original hash and S3 hash
        if original_hash == s3_hash:
            print("File integrity check passed.")
            return bucket_name, s3_key
        else:
            print("File integrity check failed: hashes do not match.")
            return None, None

    except requests.exceptions.RequestException as download_error:
        print(f"Error downloading file: {download_error}")
        return None, None
    except Exception as e:
        print(f"Error during upload: {e}")
        return None, None

# Function to calculate SHA256 hash
def calculate_sha256_hash(response, total_size):
    sha256_hash = hashlib.sha256()
    downloaded = 0
    print("Calculating file hash...")

    for chunk in response.iter_content(chunk_size=8192):
        sha256_hash.update(chunk)
        downloaded += len(chunk)

        # Print progress every 100 MB
        if downloaded % (100 * 1024 * 1024) == 0:
            print(f"Downloaded {downloaded / (1024 * 1024)} MB for hash calculation")

    return sha256_hash.hexdigest()

# Function to calculate SHA256 hash from an S3 object
def calculate_sha256_hash_from_s3(bucket_name, s3_key):
    s3 = boto3.client('s3')
    sha256_hash = hashlib.sha256()

    try:
        # Download file from S3 in chunks and update the hash
        s3_object = s3.get_object(Bucket=bucket_name, Key=s3_key)
        file_stream = s3_object['Body']

        print("Calculating S3 file hash...")

        for chunk in iter(lambda: file_stream.read(8192), b''):
            sha256_hash.update(chunk)

        return sha256_hash.hexdigest()

    except Exception as e:
        print(f"Error calculating hash from S3: {e}")
        return None

# Progress bar class for tracking upload progress
class ProgressPercentage(object):
    def __init__(self, total_size):
        self._size = float(total_size)
        self._seen_so_far = 0
        self._lock = threading.Lock()

    def __call__(self, bytes_amount):
        with self._lock:
            self._seen_so_far += bytes_amount
            percentage = (self._seen_so_far / self._size) * 100
            sys.stdout.write(
                f"\rUploaded {self._seen_so_far} / {self._size} bytes ({percentage:.2f}%)"
            )
            sys.stdout.flush()

# Example usage
if __name__ == "__main__":
    bucket_name = 'your-s3-bucket-name'
    s3_key = 'path/in/s3/largefile.ova'  # Change this to your desired S3 key
    download_url = 'https://example.com/path-to-your-ova-file.ova'

    uploaded_bucket, uploaded_key = multi_part_upload_with_s3_from_url(bucket_name, s3_key, download_url)

    if uploaded_bucket and uploaded_key:
        print(f"\nFile successfully uploaded to bucket: {uploaded_bucket}, key: {uploaded_key}")
    else:
        print("\nFile upload failed.")
